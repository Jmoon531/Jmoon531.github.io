### 海量数据找Topk的问题？

海量数据找Topk大致有两类问题，一种就是单纯的找最大的K个数，另外一种是找出现次数最多的K个数（经典的WordCount）。这两种情况的主要区别在于，单纯的找TopK可以先找每个分块的TopK，然后最后找一个总的TopK；但是找出现次数最多的TopK却不行，必须要最后把所有分块的计算结果合并之后再找TopK，以下分别对这两个问题进行讨论。

#### 10亿个数，找最大的K个数？

10亿=10^9，大概等于2^30，显然int类型的取值范围肯定是超过10亿的，如果数的类型是int，那么10亿个int大概需要4GB的存储空间。

**单机**

如果单机内存装得下，我们可以使用直接将数据全部加载到内存，单线程下除了全排序之外，我们还可以使用另外两种方法：

1. 使用快速排序进行划分的方法找到第k大的数即可。
2. 维护一个K个元素的小根堆，然后遍历剩下的元素，如果元素大于堆顶元素则将堆顶元素替换成该元素，然后再调整堆，这样最后遍历完所有元素之后的堆就是最大的k个数。

如果使用多线程，假设有n个线程，那么思路就是将数据分成n份，然后每个线程都使用上述方法找到TopK，最后由主线程从所有的TopK中找到最后的TopK。

如果单机内存装不下，上述方法依然使用，只不过需要将数据分批读进内存，然后使用上述方法找TopK，最后再从所有的TopK中找到最后的TopK。

**多机**

多级和上述多线程找TopK的思想一样，只不过数据在多台主机的不同线程上处理而已。这里可以使用分布式计算框架来编程程序，这样就不用自己从头实现多机分布式计算协调处理的代码，只要关注主要的计算逻辑即可。

#### 4G字符串找出现次数最多的100个？

首先是WordCount部分，即计算每个字符串出现的次数，这里同样也可以分单机多线程或者多机的分布式计算两种形式来讨论。

单机单线程就是把单机多线程的处理步骤分步进行完成，所以就不再过多进行阐述了，这里直接讨论单机多线程并且内存只有512M可用的情况下的处理流程：

直接读入512M数据到内存，然后每个线程平分处理这些数据，处理的流程就是遍历加入到各自的HashMap中，最后由主线程将所有的HashMap合并。然后再读取下一个512M进行处理。

最后把所有的HashMap合并，然后使用上一个找TopK的方法来找出现次数最多的K个数即可。

上述方法有个可能出现的问题，那就是算最终结果的时候，内存可以放不下所有HashMap，出现这种情况的原因就是每次的512M分块字符串的重复率太低的，导致得到HashMap太大了。解决的方法就是可以先将HashMap保存保存到外存中，不过在保存时再使用Hash分桶的思想，把key分散在不同的桶里（桶可以是文件夹，或者是文件。如果是文件夹，那么每次保存都生成一个文件，如果是文件，那么每次保存都追加写到上一次保存的文件中），最后合并的时候，先读取一个桶的数据进行合并，然后将所有桶的数据进行合并。

多机分布式计算思想和单机多线程差不多，这里同样可以借助于分布式计算框架来完成，主要就是MapReduce的思想，Map端先处理数据，然后Hash分桶发送不同的reduce进行聚合，每个Reduce输出TopK，最后再聚合一次，也就是找最后的TopK。

### 简单说一下Presto和SparkSQL的区别？

Presto和SparkSQL都是基于内存的分布式计算引擎，简单理解它俩的区别就是，Presto的架构很直接，它是专门为大数据场景SQL查询定制的**分布式SQL查询引擎**，而SparkSQL是构建在SparkCore上的，SparkCore是一个可以处理结构化和半结构化数据的计算引擎，通用性更强，SparkSQL通过将SQL翻译成SparkCore的RDD算子来执行，所以通常来讲SparkSQL在执行性能上可能要稍逊于Presto，因为presto专用性更强，针对sql和结构化数据有更好的优化，而Spark因为要兼顾通用性，所以需要在处理SQL和结构化数据上牺牲一点性能，构建在SparkCore上的应用不仅有SparkSQL，还有Spark Streaming、Spark MLib、Spark GraphX。

更细节一点：

架构方面，Presto的主从节点常驻内存，时刻准备着接收SQL查询，但是SparkSQL转换成SparkRDD任务之后需要Yarn等资源调度器调度执行，对集群资源的利用Presto要做的更好。（on yarn模式也可以做到常驻内存，即分配完资源以后不释放就行，一直运行就可以，所以常驻内存不算是优点。）

但Presto并不是样样都比Spark SQL强，针对复杂查询的时候，SparkSQL有基于成本的优化，比Presto做的要好；另外，Presto为了尽可能降低SQL查询的延时，放弃了容错机制，而Spark的容错做的很好，所以当任务出错的时候，Presto需要重启，而SparkSQL不需要，但这也造成Spark SQL生成SQL执行计划以及调度开销都要比Presto高很多。

总结来说，Spark更适合处理非结构化数据，Presto专注于大数据的SQL查询。

### Presto、SparkSQL与ClickHouse、Druid的区别？

首先他们都是构建OLAP的相关技术，其次它们是针对不同的应用场景设计的架构，导致他们的长处也各不相同，不存在一个技术适配所有场景的说法。

Presto、SparkSQL是计算引擎，不涉及存储，可以对接多种数据源，而ClickHouse、Druid是存储计算一体的。因为ClickHouse和Druid是存储计算一体的，所以它俩针对查询设计有专门的存储格式，优点是查询延时低，但是缺点是支持数据量不大（这里的不大是针对Presto、SparkSQL而言的，对于传统针对OLTP场景的数据库来说，算是很大了），并且也不适合复杂查询。Presto 和 SparkSQL专注于计算，能处理更大数据量，对数据的存储格式也没有要求，可以进行复杂查询，但缺点是查询延时高。

所以Presto、SparkSQL适合数仓例行任务，因为都是复杂查询，并且对延时没有啥太大的要求；ClickHouse、Druid适合用于BI工具的底层。

### Kylin维度爆炸？

### CAP？

CAP定理描述了一个分布式的系统中，涉及共享数据问题时，以下三个特性最多只能同时满足其中两个：

- **一致性**（**C**onsistency）：代表数据在任何时刻、任何分布式节点中所看到的都是符合预期的。一致性有两种情况：面向副本复制的一致性 和 面向数据库状态的一致性。
- **可用性**（**A**vailability）：代表系统不间断地提供服务的能力。
- **分区容忍性**（**P**artition Tolerance）：代表分布式环境中部分节点因网络原因而彼此失联后，即与其他节点形成“网络分区”时，系统仍能正确地提供服务的能力。

P 是分布式网络的天然属性，永远可靠的通信在分布式系统中必定不成立的，这不是你想不想的问题，而是只要用到网络来共享数据，分区现象就会始终存在。所以必须P是必须保的，也就是在发生网络分区的时候系统必须要有提供服务的能力，不然就不能称之为分布式系统，于是接下来就只能在C 和 A之间进行权衡。

**CP**：保C，放弃A。意味着在数据达到一致性之前系统不能对外提供服务，HBase 就是属于 CP 系统，以 HBase 集群为例，假如某个 RegionServer 宕机了，这个 RegionServer 持有的所有键值范围都将离线，直到数据恢复过程完成为止，这个过程要消耗的时间是无法预先估计的。

**AP**：保A，放弃C。意味着系统时刻对外提供服务，但不保证数据的一致性，也就是可能有些请求返回的数据是错的。选择放弃一致性的 AP 系统目前是设计分布式系统的主流选择，因为 P 是分布式网络的天然属性，你再不想要也无法丢弃，而 A 通常是建设分布式的目的，目前大多数 NoSQL 库和支持分布式的缓存框架都是 AP 系统，以 Redis 集群为例，如果某个 Redis 节点出现网络分区，那仍不妨碍各个节点以自己本地存储的数据对外提供缓存服务，但这时有可能出现请求分配到不同节点时返回给客户端的是不一致的数据。

虽然”一致性”通常是被牺牲、被放弃的那一项属性，但无论如何，我们建设信息系统，终究还是要确保操作结果至少在最终交付的时候是正确的，也就是允许数据在中间过程出错（不一致），但应该在输出时被修正过来，即把牺牲了 C 的 AP 系统又要尽可能获得正确的结果的行为称为追求“弱一致性” 或者 **“最终一致性”**，于是演化成了**BASE理论**。

#### Kafka是AP还是CP?

如果把Kafka设置成保证生产者和Kafka之间消息不丢失，那么此时Kafka就是CP。

> 1. 设置Producer端设置`acks`=all
> 2. topic设置`replication.factor`>=3
> 3. 设置`min.insync.replicas`>1
> 4. 设置`unclean.leader.election.enable`=false，即不允许Unclean leader选举

除此之外，如果把`acks`设置为0或者1，那么此时Kafka就是AP。

总结，包括Kafka在内的很多分布式系统其实都不是严格AP或者CP系统。
