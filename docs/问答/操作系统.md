#### 进程和线程的区别？

线程概念还没有提出来的时候，如果想要在完成一个任务的同时充分利用cpu的计算资源，可以开启多个进程，这时进程不仅是调度的单位，还是资源分配的单位。

作为调度的单位，如果是运行在单核cpu上，当某个进程因需要等待IO完成，操作系统就可以先把它挂起，把cpu资源让出来给其它进程执行，从而充分利用了cpu的计算资源，如果是多核cpu，这些进程还可以并行执行。这样虽然可以充分利用cpu的计算资源，但是在对进程进行调度时，上下文切换的代价太大。

作为资源分配的单位，每个进程拥有自己独立的地址空间，互补干扰，因为创建多个进程是为共同完成同一件事情，所以进程之间免不了要进行信息的交流，这时只能依靠进程间的通信完成，比如需要依靠信号量完成同步互斥、需要依靠消息队列或者共享内存等方式完成数据的传递。这种通信不仅代价大，因为都是系统调用，需要从用户态切换到内核态，而且编程模型还比较复杂，远没有像线程直接依靠共享地址空间那样来的直接方便。

所以线程就被提出来了，一个进程中可以包含多个线程，线程作为资源调度的单位，进程就不再被作为调度的单位，只作为资源分配的单位，各个线程共享进程的地址空间（如Java中的堆和方法区），每个线程只保留少量自己私有的资源（如Java中的栈和程序计算器）。线程引入之后，可以依靠多个线程来合作完成之前用多个进程完成的工作。

线程解决了之前进程切换开销大的问题，因为线程切换需要保留的执行现场只是自己拥有的哪些少留的资源，并不需要管整个进程。线程之间协作完成某项工作也不需要像进程直接通信那么麻烦了，直接依靠共享的地址空间即可。

#### 解释一下孤儿进程和僵尸进程？

孤儿进程：一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。

僵尸进程：一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵死进程。

> [孤儿进程与僵尸进程总结](https://www.cnblogs.com/Anker/p/3271773.html)

#### 操作系统线程实现的方式，Java是哪一种？

操作系统线程实现的方式有1:1实现、N:1实现、N:M实现。

- 1:1实现特点：需要操作系统内核支持线程；用户线程会1:1映射到操作系统的内核线程上，所以用户线程的需要依靠操作系统的调度，需要在用户态和内核态之间来回切换，开销比较大。

- N:1实现特点：不需要操作系统内核支持线程，只需要函数库支持就行，也就是在不支持线程只支持进程的操作系统上也能实现这种方式，所以这种实现方式称为用户线程。用户线程的创建、调度和销毁完全在用户态完成，开销更小。

- N:M实现特点：综合以上两种方式的优点。

主流Java虚拟机采用的是1:1，这当然是需要操作系统也支持1:1，非主流的JVM也有支持1:N实现、N:M实现的。

#### 进程之间的通信的方式？

1. 信号
   
   在Linux 中信号发送和捕获的系统调用，这是一种在早期unix系统里面就存在的通信方式，shell命令kill -9就是在向进程发送结束的信号。

2. 管道
   
   无名管道仅用于父子进程或兄弟进程之间的数据传递。早期unix的无名管道只支持半双工方式，但是现代unix支持全双工方式了。
   
   有名管道也称FIFO管道，有名管道和无名管道本质一样，只不过有名管道会在文件系统中生成一个目录项，于是就可以允许与其它不具有亲缘关系的进程进行通信了。

3. 消息队列

4. 共享存储区

5. 信号量

6. 套接字

#### 用户态和内核态？

简单的理解就是用户态时cpu执行的是用户代码，内核态时cpu执行的是操作系统的代码，区别就是在内核态比用户态具有更高的权限，能够执行一些特权指令。

本质上就是cpu有一个状态指示寄存器，这个寄存器的值控制着CPU当前的工作状态（ring0、ring1、ring2、ring3），cpu在不同的状态下能执行不同级别的指令，改变这个寄存器的值就是所谓的内核态和用户态的切换。

系统调用会导致进程从用户态切换到内核态。

CAS操作在X86下依靠的是cmpxchg指令，这条指令并不是特权指令，所以完全可以在用户态下执行，于是CAS操作并不会导致用户态到内核态的切换。

#### 进程的上下文切换？

进程之间进行切换时，会将cpu中各种寄存器的值保存到PCB中。

##### 模式切换：

用户态到内核态的切换并没有进行进程的上下文切换，因为系统调用使得进程从用户态进入内核态是在一个进程中完成的，只不过是用户态执行的用户代码，而内核态执行的是操作系统的代码。但是用户态到内核态的切换会改变程序执行的栈空间，即从用户空间的用户栈切换到内核空间的内核栈，因为执行的不同的代码，改变栈空间底层其实就是改变cpu中有关地址的寄存器的值，也就是说用户态到内核态的切换会进行寄存器的上下文切换，只不过相比于进程的上下文切换，寄存器上下文切换的代价要更低，把用户态到内核态的切换称为模式切换，可以将其看作是一种特殊的上下文切换。

#### 解释一下文件的逻辑结构和物理结构？用户程序从磁盘上读取数据的流程？

程序员在写代码时其实考虑的都是文件的逻辑结构，比如顺序文件，索引文件（什么一级索引，多级索引，B树索引，Hash索引都是文件的逻辑结构），也就是程序在写代码时思考如何从文件中读数据时，脑袋里面装的都是文件的逻辑，把文件视为一个整体，一整块的。

比如对于逻辑结构包含索引的文件，程序员写代码时首先会使用c语言的read系统调用读文件中的索引，传入的参数是索引在哪个文件、相对于文件开头多少偏移、多少字节的数据，这些都是在根据文件的逻辑在思考数据的位置。

然后从用户态切换到内核态，操作系统开始根据文件的物理结构来读数据的。

首先是操作系统根据第一个参数即文件的绝对路径找文件，过程是，根据缓存在内核空间的根目录文件找到二级目录的inode节点，然后启动磁盘IO从磁盘的索引节点区读取索引节点到内核空间，接着就可以根据索引节点找到二级目录对应的文件在磁盘文件数据区所在的位置了，然后再启动磁盘IO读取这个目录文件，再根据这个目录文件中的数据找三级目录的inode节点，一直这样操作系统就可以找到你要读取的文件的索引节点了。

然后操作系统根据第二、三个参数在inode节点中找到你所要读取数据块，接着启动磁盘IO将数据块从磁盘读到操作系统内核空间，最后把数据从内核空间拷贝到用户空间。

于是你就拿到文件逻辑的索引了，接着你根据这个索引找到你所需要数据的位置，这个位置也是相对于文件开头多少偏移，然后你拿着这个逻辑地址继续调用read系统调用，操作系统重复上面的步骤，于是你就拿到数据了。

所以文件的逻辑结构和物理结构都会影响文件的读取数据。

#### 为什么要有虚拟内存？

如果没有虚拟内存，需要将整个程序都装进内存才能运行，这样就会因为内存容量的限制，导致装入内存的程序有限，从而cpu的利用率就会大大降低，因为可并发执行程序有限，一旦所有在内存中的程序由于IO阻塞了，那么cpu就完全处于空闲状态了，有了虚拟内存之后，将程序部分转入内存就可运行了，这样同时转入内存的程序的数量就大大增加了，当程序执行到某处要将逻辑地址经页表转换成物理地址时，发现页表该逻辑地址对应的物理地址不存在，就会发生缺页中断，这个时候操作系统会将外存的页调到内存。

#### 内存的管理方式有哪些？

无论是内存还是外存，对存储空间的管理，都有两个方面，一是对正在使用的空间的管理，另一个是对没有使用的空间的管理。对内存正在使用的空间的管理方式就是页表和段表，对内存未使用空间的管理方式是一些动态分区分配算法，比如首次适应算法、循环首次适应算法、伙伴系统等。

#### 外存的管理方式？

对已使用的空间的管理方式有 Windows的FAT、NTFS，unix的增量式索引。对未使用空间的管理方式有空闲链表法、位示图法、成组链接法。

#### 页表和段表？

如果没有虚拟内存，需要将整个程序都装进内存才能运行，这时，如果是内存不是段式或页式的管理方式，那么需要给程序分配连续的内存空间，因为需要一次性将程序中的逻辑地址转变成内存物理地址，如果内存是段式或页式的管理方式，那么不必先进行地址转换，运行的时候再通过页表或段表进行逻辑地址到内存物理地址的转换。

#### DMA？

没有DMA时，外部IO设备的数据到内存需要CPU的参与，过程是CPU先把外部设备的数据读到CPU寄存器，然后再把CPU寄存器的数据写到内存。此时的IO有两种方式（以磁盘IO为例）：

1. 轮询方式：操作系统调用磁盘驱动程序后，会一直轮询检查磁盘控制器缓冲区（外部IO设备都有自己的缓冲区，容量并不大）有没有准备好，如果准备好了就把数据拷贝到内核缓冲区（PageCache）中。

2. 中断方式：此种方式操作系统不会一直轮询，而是在调用磁盘驱动程序后直接返回，当磁盘控制器缓冲区中的数据准备好之后会给操作系统发送一个中断信号，然后由CPU响应中断，这时CPU会把磁盘缓冲区中的数据拷贝到CPU寄存器，然后再写到内核缓冲区中。

有了DMA之后，外部IO设备的数据到内存就不需要CPU参与了，而是由DMA直接控制，DMA将数据从外部IO设备拷贝到内核缓冲区之后会给CPU发送中断信号。

注意：DMA的作用是将外部IO设备的数据拷贝到内存，内存中数据的复制与DMA无关，内存中数据的复制需要经过CPU，也就是数据在内核缓冲区中的复制，以及数据从内核缓冲区到用户地址空间的复制都是在CPU的控制下完成的。

#### PageCache?

PageCache就是操作系统内核缓冲区中缓存外部IO设备数据的部分，使用操作系统的系统调用读取外部设备数据时，操作首先会将数据读到PageCache，然后再由CPU将数据复制到用户地址空间，这种IO方式也称为缓存IO。

当然操作系统也提供了绕开PageCache的IO方式，称为直接IO，也就是外部设备直接与用户空间的缓冲区进行IO。用户态直接 I/O 只能适用于不需要内核缓冲区处理的应用程序，这些应用程序通常在进程地址空间有自己的数据缓存机制，称为自缓存应用程序，如数据库管理系统就是一个代表（MySQL的buffer pool）。另外，异步IO方式支持直接IO。

使用PageCache的好处：

1. **缓存命中，减少读。**PageCache中缓存的是最近被访问的数据，根据程序运行的局部性，刚被访问的数据在短时间内再次被访问的概率很高，所以当下次访问同样的数据时，操作系统不必再次进行IO，而是直接PageCache中缓存的数据拷贝到用户地址空间即可。

2. **预读，减少读。**PageCache提供预读功能，所谓的预读功能就是，磁盘IO时操作系统会多读一点数据。比如你只想读32KB的数据，进行一次系统调用，操作系统可能会读取64KB的数据到PageCache中。

3. **顺序写，减少随机写。**操作系统的 I/O 调度算法会缓存尽可能多的 I/O 请求在PageCahche，最后合并成一个更大的 I/O 请求再发给磁盘，减少随机写，增加顺序写。

#### 零拷贝技术？

从磁盘读数据，然后写到网络设备中发出去，read+write是最传统的方式，以下是实现零拷贝常用的技术：

1. mmap+write：直接将数据从 内核读缓冲区 拷贝到 内核写缓冲区，减少了一次将数据从内核缓冲区拷贝到用户地址空间的成本。

2. sendfile：相比于mmap只是减少一次用户态到内核态的切换，数据同样是直接从内核的读缓冲区写到了内核写缓冲区。因为只在内核态进行，所以用户进程无法操作数据，代码上的体现就是，使用mmap是两步搞定的，所以中间可以对数据进行操作，但是使用snedfile是一次系统调用，没有操作数据的余地。

3. sendfile+SGDMA(Scatter-Gather DMA)：相比于只使用sendfile，减少了一次数据拷贝，数据直接从内核读缓冲区映射到内核写缓冲区的，仍然无法对数据进行修改。这才是真正的零拷贝（Zero-copy）技术，因为没有在内存层面去拷贝数据，也就是说全程没有通过 CPU 来搬运数据，所有的数据都是通过 DMA 来进行传输的。如果网卡支持SG-DMA（The Scatter-Gather Direct Memory Access）技术，使用sendfile() 系统调用直接就是sendfile+SGDMA的方式，如果不支持，那就是sendfile方式。

> [零拷贝技术-小林coding](https://xiaolincoding.com/os/8_network_system/zero_copy.html)

