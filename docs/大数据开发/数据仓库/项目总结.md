---

Created at: 2021-10-25
Last updated at: 2021-11-01


---

# 项目总结


**数据源 -> ODS层**
1.本项目使用 Flume+Kafka+Flume 的方案将日志传到HDFS上，使用sqoop将业务数据传到HDFS上，然后使用load命令将同步到HDFS上的文件加载到ODS层的表中。
2.从业务数据库MySQL到数仓ODS层，根据业务表的特点有3中同步方式：全量同步、增量同步、新增及变化同步。使用sqoop同步业务数据传到HDFS时需要考虑每张表属于哪种同步方式，如果是全量同步则where 1=1，如果增量同步则where create\_time=do\_date，如果是新增及变化同步则where operate\_time=do\_date or create\_time=do\_date。
3.对于用户行为日志不用考虑同步方式，因为Flume的HDFS Sink会根据Event头里面timestamp将每一天日志写到当天的分区中，相当于每日增量。
**ODS层 -> DIM层 和 DWD层**
4.因为ODS层不对数据做任何处理，只是对数据的原貌进行备份，所以无论是用户行为日志还是业务数据，ODS层都只是简单粗暴的将数据写到当日的分区中。但DIM和DWD层不能这样，因为这两层的表是维度建模的结果，是为后续对数据分析做准备的，所以DIM和DWD层需要对来自ODS层的数据进行处理，将数据以一定的策略写到DIM和DWD层表的分区中，这样才能根据分区更加高效地查询到数据。
**ODS层 -> DIM层**
5.数据来自ODS层多张全量同步表的DIM维度表，也是首日和每日直接全量同步即可。
6.数据来自ODS层新增及变化同步表的DIM维度表，需要使用拉链表来实现DIM层新增及变化的逻辑。
**ODS层 -> DWD层**
7.数据来自ODS层日志表的DWD日志表，需要将ODS层的日志拆成多张日志表，每一张DWD日志表都是有结构的，方便后续对日志进行分析。
8.数据来自ODS层全量同步表的DWD事实表称为周期型快照事实表，首日和每日直接全量同步即可。
9.数据来自ODS层增量同步表的DWD事实表称为事务型事实表，首日需要将ODS层的数据根据create\_time散开到多个分区中，每日直接同步增量数据即可。
10.数据来自ODS层新增及变化同步表的DWD事实表称为累积型快照事实表，累积型快照事实表的首日和每日同步都要根据每一条数据的状态变化将数据写到不同的分区之中，也就把状态没有终止的数据保存在最新的分区之中，把状态已经终止的数据保存在其终止日期的分区之中。
**DWD层 -> DWS层**
1.从DIM层维度表的角度出发，DWS层一张表对应于DIM层的一个维度，其的数据是DWD层与该维度关联的多张事实表的度量值的聚合值。
2.或者从DWD层事实表的角度出发，一张事实表有多个维度外键，对每个维度外键分组聚合的统计值会写到不同的DWS层的主题表中，也就是DWS层的每张主题表可以看作是对DWD层事实表不同角度的聚合。
3.对于周期型快照事实表的统计，数据一般不来自周期型快照事实表，而是来自日志表，DWD层的日志表可以看作是维度全部退化了的事务型事实表。
4.首日装载分组聚合的sql的group by需要使用 维度外键 和 时间字段，因为每个分区保存的就是当日的数据。
5.如果首日装载时的数据来自于事务型事实表，该时间字段可以是 分区字段。
6.如果首日装载时的数据来自于累积型快照事实表，如果是按照完成时间分组，那么时间字段可以使用分区字段dt（不过前提是完成的标志只是一个时间字段的取值），如果不是按完成时间分组，那么就需要按业务逻辑使用相应的时间字段分组，不过这会造成对所有分区的数据进行扫描。
7.每日装载sql的group by不在需要使用时间字段了，因为会使用where过滤出DWD层当日的数据，然后再使用其它过滤条件过滤出符合条件的数据，最后使用维度外键分组聚合。
8.如果每日装载时的数据来自于事务型事实表，那么需要先使用where dt='当日日期' 过滤出当日数据，然后再根据业务逻辑选择其它条件对当日分区中的数据进行过滤。
9.如果每日装载时的数据来自于累积型快照事实表，那么需要先使用where dt='当日日期' 过滤出当日数据，那么需要从这3个条件中选出一个：where dt='当日日期' 或者 where dt='9999-99-99' 或者 where dt='当日日期' or where dt='9999-99-99'，作为过滤出当日数据的条件，然后再根据业务逻辑选择其它条件对当日分区中的数据进行过滤。
**DWS层 -> DWT层**
1.DWS层每个分区的数据是同步日期前一日数据的聚合结果，而DWT层每个分区的数据是截止到同步日期，前1日、前7日、前30日 和 从开始至今的累积聚合值，可由DWS层数据聚合得到，所以DWT层的数据是对DWS层数据的累积聚合，DWT层每一张表的数据都来自DWS层与之对应的表。
2.DWT层首日装载直接对DWS层所哟分区聚合即可。
3.DWT层每日装载是将DWS层当日新增的数据与DWT层前一日汇总的数据进行汇总。
4.DWT层保存的是全量数据。
5.DWT层一般只会保留两个分区的数据，即两天前的数据都会删除掉。
**ADS层**
1.ADS层为报表、统计图提供数据，所以一般是对所有数据的统计，比如某日注册用户总数，某日下单总数等，而不是某个用户的统计数据。
2.ADS的统计需求不固定，于是数据数据的装载逻辑也不固定，继而ADS层没有首日装载和每日装载（或者说视具体的需求而定）。
**ADS层 -> MySQL**
由于报表系统的数据一般不是Hive，而是MySQL，所以还需要将ADS层的数据导出到MySQL中。
**工作流调度系统**
以上数据同步的脚本的调度工作由Azkaban完成。
报表系统

从用户行为这个宽泛的角度看数仓每一层的表的每一行数据表示什么？
1.ODS层保存的是原始数据，所以ODS层一行数据表示的是用户的一次行为
2.DWD层只是对ODS层按业务数据的特点重新按分区组织了数据，所以DWD层的一行数据表示的也是用户的一次行为
3.DWS层对DWD层数据轻度汇总，所以DWS层的一行数据表示的是活跃用户在这一天所有行为的累积值
4.DWT层对DWS层所有数据进行累积汇总，所以DWT层的一行数据表示的是一个用户在最近n天的所有行为的累积值，因为是对DWS层所有数据的累积，所以DWT层会保存所有用户的统计值。
5.ADS层计算的是所有用户在最近n天的一个统计值，所以ADS层的一行数据表示的最近n天所有用户的统计值。

