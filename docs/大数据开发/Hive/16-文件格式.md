---

Created at: 2021-09-04
Last updated at: 2025-03-05


---

# 16-文件格式


文件格式：
Hive 支持的存储数据的格式主要有：TEXTFILE 、SEQUENCEFILE、ORC、PARQUET。

TEXTFILE、ORC、PARQUET三种文件格式的对比实验：
测试数据是一个txt文本文件大小为18M

1\. TEXTFILE
建表，默认的存储数据格式就是TEXTFILE，可以不指定：
```
create table log_text (
   track_time string,
   url string,
   session_id string,
   referer string,
   ip string,
   end_user_id string,
   city_id string
)row format delimited fields terminated by '\t'
stored as textfile;
```
导入数据
```
load data local inpath '/opt/module/data/log.data' into table log_text;
```
查看表中数据大小，18M
```
dfs -du -h /user/hive/warehouse/log_text;
```

2.ORC
建表，存储格式是orc，orc默认开启压缩，这里把压缩先关闭：
```
create table log_orc (
   track_time string,
   url string,
   session_id string,
   referer string,
   ip string,
   end_user_id string,
   city_id string
)row format delimited fields terminated by '\t'
stored as orc
tblproperties("orc.compress"="NONE"); -- 设置 orc 存储不使用压缩
```
把上面那张表log\_text的数据插入到这张表中，非TEXTFILE格式的表只能这样做，因为load无法把TEXTFILE格式的数据导入到非TEXTFILE格式的表中，但是load可以导分区表和分桶表，load导入数据到分区表和分桶表是走MR，这里的insert也是走MR。
```
insert into table log_orc select * from log_text;
```
查看表中数据大小，7.69M
```
dfs -du -h /user/hive/warehouse/log_orc;
```

3\. Parquet
建表，存储格式是Parquet，默认 parquet没有开启压缩。
```
create table log_parquet (
   track_time string,
   url string,
   session_id string,
   referer string,
   ip string,
   end_user_id string,
   city_id string
)row format delimited fields terminated by '\t'
stored as parquet;
```
导入数据，同样需要用insert走MR
```
insert into table log_parquet select * from log_text;
```
查看表中数据大小， 13.09 MB
```
dfs -du -h /user/hive/warehouse/log_parquet;
```

三种格式存储文件的大小关系：
TEXTFILE > ORC > Parquet
三种格式文件的查询速度相当

存储格式与压缩方式结合：
创建一张存储格式是orc，压缩方式是zlib的表
```
create table log_orc_zlib (
    track_time string,
    url string,
    session_id string,
    referer string,
    ip string,
    end_user_id string,
    city_id string
)row format delimited fields terminated by '\t'
stored as orc
tblproperties("orc.compress"="ZLIB");
```
导入数据
```
insert into log_orc_zlib select * from log_text;
```
查看大小为2.78 MB

创建一张存储格式是orc，压缩方式是snappy的表
```
create table log_orc_snappy (
    track_time string,
    url string,
    session_id string,
    referer string,
    ip string,
    end_user_id string,
    city_id string
)row format delimited fields terminated by '\t'
stored as orc
tblproperties("orc.compress"="snappy");
```
导入数据，查看大小为 3.75 MB

创建一张存储格式是parquet，压缩方式是snappy的表
```
create table log_parquet_snappy (
    track_time string,
    url string,
    session_id string,
    referer string,
    ip string,
    end_user_id string,
    city_id string
)row format delimited fields terminated by '\t'
stored as parquet
tblproperties("orc.compress"="snappy");
```
导入数据，查看大小为6.39 MB（6.39 MB是老师测的，我这里测试失败了，还没有开启snappy压缩时一样，是13.09 MB）

存储方式和压缩总结：在实际的项目开发当中，hive 表的数据存储格式一般选择：orc 或 parquet。压缩方式一 般选择 snappy，lzo。

